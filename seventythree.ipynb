{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59400, 40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def cleanski(df): \n",
    "    boolski = ['public_meeting', 'permit']\n",
    "    df['date_recorded'] = pd.to_datetime(df['date_recorded']).apply(lambda x: x.toordinal())\n",
    "    df[boolski[0]] = df[boolski[0]].map({True: 1, False: 0})\n",
    "    df[boolski[1]] = df[boolski[1]].map({True: 1, False: 0})\n",
    "    return df\n",
    "\n",
    "df_train = cleanski(pd.read_csv('train_features.csv'))#.set_index(keys='id', drop=True)\n",
    "df_test = cleanski(pd.read_csv('test_features.csv'))\n",
    "test_indices = df_test.id.to_numpy()\n",
    "\n",
    "\n",
    "target_train = pd.read_csv('train_labels.csv')#.set_index(keys='id', drop=True)\n",
    "\n",
    "print(df_train.shape)\n",
    "#assert (target_train.id == df_train.id).all()\n",
    "\n",
    "\n",
    "cats = df_train.select_dtypes(include='object').columns\n",
    "\n",
    "nums = df_train.select_dtypes(exclude='object').drop('id', axis=1).columns\n",
    "\n",
    "N = df_train.shape[0]\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')#.set_index(keys='id', drop=True)\n",
    "submit_rows = sample_submission.id.to_numpy()\n",
    "assert (submit_rows == test_indices).all()\n",
    "\n",
    "\n",
    "# df_train[nums].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [x==0 for x in df_train[nums].isna().sum()] # omit imputer for numeric\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[ \n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not_known')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "     transformers=[\n",
    "         ('num', numerical_transformer, nums),\n",
    "         ('cat', categorical_transformer, cats)])\n",
    "\n",
    "\n",
    "# # Append classifier to preprocessing pipeline.\n",
    "# # Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', SGDClassifier(loss='log', tol=np.exp(-10), max_iter=100000))])\n",
    "\n",
    "grid_params = {\n",
    "    'classifier__alpha': [np.exp(k) for k in range(-5, 6, 2)], \n",
    "}\n",
    "\n",
    "search = GridSearchCV(clf, param_grid=grid_params, iid=False, cv=7, return_train_score=True, n_jobs=3, verbose=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 4 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=3)]: Done  28 out of  28 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done  28 out of  28 | elapsed:  1.1min finished\n",
      "/home/quinn/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.36 s, sys: 307 ms, total: 9.66 s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#X_train, X_test, y_train, y_test = train_test_split(df_train, target_train)\n",
    "\n",
    "search.fit(df_train.drop('id', axis=1), target_train.drop('id', axis=1))\n",
    "\n",
    "prediction = {x: s for x,s in zip(df_test.id.to_numpy(), search.predict(df_test))}\n",
    "\n",
    "\n",
    "# target_train.to_numpy().reshape(-1,1).T.shape\n",
    "\n",
    "# target_train.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  50785  non functional\n",
       "1  51630      functional\n",
       "2  17168  non functional\n",
       "3  45559  non functional\n",
       "4  49871      functional"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction \n",
    "#print(prediction.shape, target_train.shape, sample_submission.id.to_numpy().shape)\n",
    "\n",
    "# submit_predictions = {}\n",
    "# for k in submit_rows: \n",
    "#     submit_predictions[k] = prediction[k]\n",
    "\n",
    "submit_df = (pd.DataFrame.from_dict(prediction, orient='index')\n",
    "             .reset_index()\n",
    "             .rename(mapper={'index': 'id', 0: 'status_group'}, axis=1))\n",
    "\n",
    "submit_df.head()\n",
    "\n",
    "#sample_submission.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 255k/255k [00:01<00:00, 239kB/s]\n",
      "Successfully submitted to DS1 Predictive Modeling Challenge"
     ]
    }
   ],
   "source": [
    "def write_submit(model, name='submission.csv'): \n",
    "    model.to_csv(name, index=False)\n",
    "    !kaggle competitions submit -c ds1-predictive-modeling-challenge -f submission.csv -m \"basic pipeline\"\n",
    "    pass \n",
    "\n",
    "write_submit(submit_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
